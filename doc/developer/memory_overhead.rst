*****************************
Memory overhead of containers
*****************************

Sarus assembles the OCI bundle for the container inside an :ref:`in-memory
temporary filesystem <config-reference-ramFilesystemType>`. Instantiating a
container from a RAM filesystem might suggest the fact that Sarus containers
impose a large overhead on system memory, as the filesystem of each container
eats up RAM resources.

However, this is not the case. The great majority of the container's rootfs is
formed by filesystem mounts: the contents of the image are loop mounted from the
squashfs file, and additional directories are bind mounted from the host (either
by Sarus site and user mounts, or by OCI hooks customizing the container).
The loop mount allows the squashfs file to be accessed as a block device, so the
image is not transferred into the in-memory filesystem.

Only a small amount of configuration files and the contents of the OverlayFS
working directory occupy real space within the in-memory filesystem.

Thus, the memory overhead of Sarus containers is in principle very limited.
Nonetheless, the files generated by the user or the applications after container
startup reside in the upper layer of the OverlayFS, and *will* take away space
from the system RAM.

An example
==========
To demonstrate the concepts explained above, consider the following example.
We are going to run multiple containers using the ``uber/horovod:0.15.2-tf1.12.0-torch1.0.0-py3.5``
image:

.. code-block:: bash

    $ sarus run --tty uber/horovod:0.15.2-tf1.12.0-torch1.0.0-py3.5 bash
    $ du -h -d1 --si /
     7.6M    /bin
     512     /boot
     1.5M    /etc
     66k     /examples
     512     /home
     25M     /lib
     1.1k    /lib64
     512     /media
     512     /mnt
     512     /opt
     0       /proc
     936M    /root
     5.7k    /run
     3.6M    /sbin
     512     /srv
     0       /sys
     512     /tmp
     5.1G    /usr
     63M     /var
     0       /dev
     6.1G    /

    $ exit

As we can see, the filesystem size of this container is 6.1GB. This installation
of Sarus is configured to not use any hook or custom bind mount from the host,
so the numbers we are seeing come exclusively from the image and from basic
container setup.

We have at our disposal a host system with 65GB of memory:

.. code-block:: bash

    $ free -h --si
              total     used     free    shared  buff/cache   available
     Mem:       65G     1.6G      58G       75M        5.3G         63G
     Swap:      24G       0B      24G

This system does not have a workload manager installed, so we open 6
terminals: on 5 of them we run Sarus containers, while from the last one we
monitor memory usage on the host. Since the container filesystem measures
6.1 GB, if the in-memory rootfs used actual space, we would expect to see a
decrease in available memory of more than 30 GB:

.. code-block:: bash

    # Launch this command in 5 different terminals
    $ sarus run --tty uber/horovod:0.15.2-tf1.12.0-torch1.0.0-py3.5 bash

.. code-block:: bash

    # Monitor memory usage on host from 6th terminal
    $ free -h --si
              total     used     free    shared  buff/cache   available
     Mem:       65G     1.6G      58G       76M        5.4G         63G
     Swap:      24G       0B      24G

We observe only small increases in shared memory and memory dedicated to kernel
buffers and page caches. Now, while the 5 containers are still running, we
create a 10GiB file in one of them and measure again memory usage on the host:

.. code-block:: bash

    # Create 10GB file in one of the containers
    $ dd if=/dev/zero of=10G.file bs=64M count=160
     160+0 records in
     160+0 records out
     10737418240 bytes (11 GB, 10 GiB) copied, 4.02419 s, 2.7 GB/s

.. code-block:: bash

    # Monitor memory usage on host
    $ free -h --si
              total     used     free    shared  buff/cache   available
     Mem:       65G     1.6G      48G       10G         15G         53G
     Swap:      24G       0B      24G

We can see that the available memory is decreased by roughly 10GB, while the
usage of shared memory (which is mainly the memory used by tmpfs) increased of
the same amount. If we delete the ``10G.file``, we can reclaim the memory we
just used:

.. code-block:: bash

    # Container
    $ rm 10G.file

.. code-block:: bash

    # Host
    $ free -h --si
              total     used     free    shared  buff/cache   available
     Mem:       65G     1.6G      58G       76M        5.4G         63G
     Swap:      24G       0B      24G

Exiting all the containers has a minimal impact on memory availability:

.. code-block:: bash

    # In each of the 5 containers
    $ exit

.. code-block:: bash

    # Host
    $ free -h --si
              total     used     free    shared  buff/cache   available
     Mem:       65G     1.6G      58G       75M        5.3G         63G
     Swap:      24G       0B      24G
